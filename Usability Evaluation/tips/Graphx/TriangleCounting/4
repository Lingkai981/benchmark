Key API Functions
GraphLoader.edgeListFile
This function is used to load a graph from an edge list file.

Parameters:

sc: The Spark context.
path: The path to the edge list file.
canonicalOrientation (optional): If true, ensures that each edge is oriented from the smaller vertex ID to the larger vertex ID.
numEdgePartitions (optional): The number of edge partitions to create.
Example:


val graph = GraphLoader.edgeListFile(sc, "data/test/followers.txt", true)
Graph.partitionBy
This function is used to partition the graph according to a given strategy.

Parameters:

partitionStrategy: The strategy to use for partitioning the graph.
Example:


val partitionedGraph = graph.partitionBy(PartitionStrategy.RandomVertexCut)
Graph.triangleCount
This function computes the number of triangles passing through each vertex in the graph.

Returns: A new graph with vertex attributes containing the triangle count.

Example:


val triCounts = graph.triangleCount().vertices
RDD.join
This function joins two RDDs by their keys.

Parameters:
other: The other RDD to join with.
Example:

val users = sc.textFile("data/test/users.txt").map { line =>
  val fields = line.split(",")
  (fields(0).toLong, fields(1))
}
val triCountByUsername = users.join(triCounts)
RDD.map
This function applies a function to each element of the RDD.

Parameters:
f: The function to apply to each element.
Example:

val triCountByUsername = users.join(triCounts).map { case (id, (username, tc)) =>
  (username, tc)
}
RDD.collect
This function collects all elements of the RDD to the driver.

Returns: An array of the collected elements.

Example:


println(triCountByUsername.collect().mkString("\n"))


Here is the pseudocode:

1: function LOAD_GRAPH(path, sc):

return GraphLoader.edgeListFile(sc, path, true)
2: function PARTITION_GRAPH(graph):

return graph.partitionBy(PartitionStrategy.RandomVertexCut)
3: function COUNT_TRIANGLES(graph):

return graph.triangleCount().vertices
4: function LOAD_USERS(path, sc):

return sc.textFile(path).map(line => (line.split(",")(0).toLong, line.split(",")(1)))
5: function JOIN_TRIANGLE_COUNTS(users, triCounts):

return users.join(triCounts).map { case (id, (username, tc)) => (username, tc) }
6: function PRINT_RESULTS(triCountByUsername):

print triCountByUsername.collect().mkString("\n")
7: function MAIN():

initialize spark = SparkSession.builder().appName("TriangleCountingExample").getOrCreate()
initialize sc = spark.sparkContext
load graph graph = LOAD_GRAPH("data/test/followers.txt", sc)
partition graph partitionedGraph = PARTITION_GRAPH(graph)
count triangles triCounts = COUNT_TRIANGLES(partitionedGraph)
load users users = LOAD_USERS("data/test/users.txt", sc)
join triangle counts triCountByUsername = JOIN_TRIANGLE_COUNTS(users, triCounts)
print results PRINT_RESULTS(triCountByUsername)
stop Spark session spark.stop()
8: run MAIN()